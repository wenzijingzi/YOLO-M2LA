# YOLO-M2LA: Advancing Bus Front-View Object Detection for Intelligent Public Transportation
#ABSTRACT:
#In the field of intelligent transportation, deep learning-based object detection has made rapid progress. However, most existing benchmarks and detectors are designed from the private-car perspective, overlooking the unique challenges of the bus front-view.In this scenario, pedestrians and riders typically appear as small and occluded targets, whereas motor vehicles dominate the medium- and large-scale categories, leading to highly complex and heterogeneous traffic flows near bus stops and intersections. To fill this gap, we construct the Bus Front-View Dataset (BFVD), collected by bus-mounted cameras under diverse environmental conditions. BFVD provides high-resolution annotations across five key categories, containing 8,131 images and 56,137 objects. It particularly emphasizes dense pedestrian regions, non-motorized participants, and frequent occlusion, offering a realistic benchmark for public transportation safety. On the methodological side, we propose YOLO-M2LA, an improved detection framework tailored for bus front-view scenarios. Extensive experiments on BFVD and multiple public benchmarks demonstrate that YOLO-M2LA outperforms state-of-the-art methods in both precision and recall, with especially notable improvements for small-scale and occluded targets. These results highlight the dual contribution of BFVD as a challenging benchmark and YOLO-M2LA as a robust detection architecture, jointly advancing safety-critical bus-oriented perception in intelligent transportation.




#Bus Front-View Dataset
#https://drive.google.com/drive/folders/1W7lCf7hhiq1xI5iRfB_51-dr1emCBYIA?usp=sharing
